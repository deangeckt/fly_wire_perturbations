{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvis_cell_type_pert import FlyvisCellTypePert, PerturbationType\n",
    "from flyvis.datasets.sintel import MultiTaskSintel\n",
    "from pathlib import Path\n",
    "import os\n",
    "import h5py\n",
    "import datamate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b9ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/flyvis_data\")\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "env = os.environ.copy()\n",
    "env[\"FLYVIS_ROOT_DIR\"] = str(data_path)\n",
    "\n",
    "def fixed_write_h5(path, val):\n",
    "    \"\"\"\n",
    "    A Windows-safe replacement that skips the 'read-before-write' check.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with h5py.File(path, mode=\"w\", libver=\"latest\") as f:\n",
    "        f.create_dataset(\"data\", data=val)\n",
    "\n",
    "datamate.io._write_h5 = fixed_write_h5\n",
    "if hasattr(datamate.directory, \"_write_h5\"):\n",
    "    datamate.directory._write_h5 = fixed_write_h5\n",
    "    print(\" -> Patched datamate.directory._write_h5\")\n",
    "else:\n",
    "    print(\" -> Warning: Could not find _write_h5 in directory module\")\n",
    "\n",
    "print(\"Importing flyvis...\")\n",
    "from flyvis import NetworkView\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0186b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing Sintel dataset...\")\n",
    "\n",
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=1,  # Use 1 for faster testing, 3 for full dataset\n",
    "    n_frames=19,\n",
    "    dt=1/50,  # Temporal resolution\n",
    "    augment=False,  # Set to False for evaluation\n",
    "    resampling=True,\n",
    "    interpolate=True,\n",
    "    all_frames=False,\n",
    "    random_temporal_crop=False,\n",
    ")\n",
    "\n",
    "print(f\"Dataset initialized with {len(dataset)} sequences\")\n",
    "if hasattr(dataset, 'arg_df'):\n",
    "    print(f\"First 5 sequences: {dataset.arg_df['name'].tolist()[:5]}\")\n",
    "    display(dataset.arg_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Inspect a Single Sample\n",
    "print(\"\\nInspecting first sample...\")\n",
    "sample = dataset[0]\n",
    "print(f\"Sample keys: {sample.keys()}\")\n",
    "print(f\"Luminance shape: {sample['lum'].shape}\")\n",
    "print(f\"Flow shape: {sample['flow'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ce7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  %% Load Network and Decoder\n",
    "print(\"\\nLoading network...\")\n",
    "src_folder = data_path / \"results/flow/0000/000\"\n",
    "network_view = NetworkView(src_folder)\n",
    "network = network_view.init_network()\n",
    "\n",
    "print(\"Loading decoder...\")\n",
    "decoder = network_view.init_decoder()[\"flow\"]\n",
    "decoder.eval()\n",
    "\n",
    "print(f\"Network initialized successfully\")\n",
    "print(f\"Number of network parameters: {sum(p.numel() for p in network.parameters())}\")\n",
    "print(f\"Number of decoder parameters: {sum(p.numel() for p in decoder.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b27210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Test Single Sequence Prediction\n",
    "print(\"\\nTesting prediction on first sequence...\")\n",
    "data = dataset[0]\n",
    "lum = data[\"lum\"]\n",
    "flow = data[\"flow\"]\n",
    "\n",
    "# Simulate network response\n",
    "stationary_state = network.fade_in_state(1.0, dataset.dt, lum[[0]])\n",
    "responses = network.simulate(lum[None], dataset.dt, initial_state=stationary_state)\n",
    "\n",
    "# Decode flow from neural responses\n",
    "y_pred = decoder(responses)\n",
    "\n",
    "# Compute EPE for this sequence\n",
    "epe = torch.sqrt(((y_pred - flow) ** 2).sum(dim=1))\n",
    "\n",
    "print(f\"Prediction shape: {y_pred.shape}\")\n",
    "print(f\"Ground truth shape: {flow.shape}\")\n",
    "print(f\"EPE shape: {epe.shape}\")\n",
    "print(f\"Mean EPE: {epe.mean().item():.4f} pixels\")\n",
    "print(f\"Median EPE: {epe.median().item():.4f} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4aa4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Full Evaluation Function\n",
    "\n",
    "# %% Define Evaluation Function\n",
    "def evaluate_network(network, decoder, dataset, output_file=None):\n",
    "    \"\"\"\n",
    "    Evaluate network on entire Sintel dataset\n",
    "    \"\"\"\n",
    "    print('Generating Sintel optic flow responses...')\n",
    "    \n",
    "    all_pred_flow = []\n",
    "    all_true_flow = []\n",
    "    all_epe = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        if i % 5 == 0:\n",
    "            print(f\"Processing sequence {i+1}/{len(dataset)}...\")\n",
    "        \n",
    "        data = dataset[i]\n",
    "        lum = data[\"lum\"]\n",
    "        flow = data[\"flow\"]\n",
    "        \n",
    "        # Simulate network response\n",
    "        stationary_state = network.fade_in_state(1.0, dataset.dt, lum[[0]])\n",
    "        responses = network.simulate(lum[None], dataset.dt, initial_state=stationary_state)\n",
    "        \n",
    "        # Decode flow from neural responses\n",
    "        y_pred = decoder(responses)\n",
    "        \n",
    "        # Compute EPE for this sequence\n",
    "        epe = torch.sqrt(((y_pred - flow) ** 2).sum(dim=1))\n",
    "        \n",
    "        all_pred_flow.append(y_pred.detach().cpu())\n",
    "        all_true_flow.append(flow.cpu() if hasattr(flow, 'cpu') else flow)\n",
    "        all_epe.append(epe.detach().cpu())\n",
    "    \n",
    "    print('Evaluating performance...')\n",
    "    \n",
    "    # Aggregate metrics\n",
    "    all_epe_tensor = torch.cat(all_epe, dim=0)\n",
    "    \n",
    "    # Compute overall statistics\n",
    "    results = []\n",
    "    \n",
    "    results.append({\n",
    "        'sequence': 'overall',\n",
    "        'n_sequences': len(dataset),\n",
    "        'mean_epe': float(all_epe_tensor.mean()),\n",
    "        'median_epe': float(all_epe_tensor.median()),\n",
    "        'std_epe': float(all_epe_tensor.std()),\n",
    "        'epe_pixel_1': float((all_epe_tensor < 1).float().mean()),\n",
    "        'epe_pixel_3': float((all_epe_tensor < 3).float().mean()),\n",
    "        'epe_pixel_5': float((all_epe_tensor < 5).float().mean()),\n",
    "    })\n",
    "    \n",
    "    # Per-sequence statistics\n",
    "    for i, epe in enumerate(all_epe):\n",
    "        results.append({\n",
    "            'sequence': f'seq_{i:03d}',\n",
    "            'sequence_name': dataset.arg_df.iloc[i]['name'] if hasattr(dataset, 'arg_df') else f'seq_{i}',\n",
    "            'mean_epe': float(epe.mean()),\n",
    "            'median_epe': float(epe.median()),\n",
    "            'std_epe': float(epe.std()),\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if output_file:\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nResults saved to {output_file}\")\n",
    "    \n",
    "    # Print summary\n",
    "    overall = results_df[results_df['sequence'] == 'overall'].iloc[0]\n",
    "    print(f\"\\nOverall Performance:\")\n",
    "    print(f\"  Mean EPE: {overall['mean_epe']:.4f} pixels\")\n",
    "    print(f\"  Median EPE: {overall['median_epe']:.4f} pixels\")\n",
    "    print(f\"  % pixels with EPE < 3px: {overall['epe_pixel_3']*100:.2f}%\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b98166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smaller dataset for quick testing\n",
    "test_dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=1,\n",
    "    n_frames=19,\n",
    "    dt=1/50,\n",
    "    augment=False,\n",
    "    resampling=True,\n",
    "    interpolate=True,\n",
    "    all_frames=False,\n",
    "    random_temporal_crop=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ecb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on first 3 sequences only for quick test\n",
    "class SubsetDataset:\n",
    "    def __init__(self, dataset, n_samples=3):\n",
    "        self.dataset = dataset\n",
    "        self.n_samples = min(n_samples, len(dataset))\n",
    "        self.dt = dataset.dt\n",
    "        self.arg_df = dataset.arg_df.iloc[:self.n_samples] if hasattr(dataset, 'arg_df') else None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "subset_dataset = SubsetDataset(test_dataset, n_samples=3)\n",
    "results_original = evaluate_network(\n",
    "    network, \n",
    "    decoder, \n",
    "    subset_dataset,\n",
    "    output_file=\"data/flyvis_data/perf/sintel_original_quick_test.csv\"\n",
    ")\n",
    "\n",
    "display(results_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511034ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Load Connectivity and Set Up Perturbation\n",
    "conn_df = pd.read_csv('data/flyvis_data/flyvis_cell_type_connectivity.csv')\n",
    "print(f\"Loaded connectivity with {len(conn_df)} connections\")\n",
    "print(f\"\\nColumns: {conn_df.columns.tolist()}\")\n",
    "\n",
    "# %% Define Perturbation\n",
    "pert = FlyvisCellTypePert()\n",
    "pairs_to_perturb = [('L4', 'L4')]\n",
    "\n",
    "pert.perturb(conn_df, PerturbationType.PAIR_WISE, pairs=pairs_to_perturb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78951605",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_folder = data_path / \"results/flow/0000/000/sintel_test/000_test_pert\"\n",
    "shutil.rmtree(tar_folder, ignore_errors=True)\n",
    "shutil.copytree(src_folder, tar_folder, dirs_exist_ok=True)\n",
    "print(f\"Created perturbed network folder: {tar_folder}\")\n",
    "\n",
    "# Apply perturbation\n",
    "print('\\nApplying perturbation to network in memory...')\n",
    "pert.override_network(network)\n",
    "\n",
    "# Save perturbed weights\n",
    "print(\"Saving perturbed weights to disk...\")\n",
    "checkpoint_template = torch.load(src_folder / \"best_chkpt\", map_location='cpu')\n",
    "perturbed_checkpoint = checkpoint_template.copy()\n",
    "perturbed_checkpoint['network'] = network.state_dict()\n",
    "\n",
    "target_best_chkpt = tar_folder / \"best_chkpt\"\n",
    "torch.save(perturbed_checkpoint, target_best_chkpt)\n",
    "print(f\" -> Updated: {target_best_chkpt}\")\n",
    "\n",
    "# Update checkpoint files\n",
    "chkpts_dir = tar_folder / \"chkpts\"\n",
    "if chkpts_dir.exists():\n",
    "    for chkpt_file in chkpts_dir.glob(\"*\"):\n",
    "        torch.save(perturbed_checkpoint, chkpt_file)\n",
    "        print(f\" -> Updated: {chkpt_file}\")\n",
    "\n",
    "# Clear caches\n",
    "print(\"Clearing caches...\")\n",
    "for cache_name in [\"__cache__\", \"__storage__\"]:\n",
    "    cache_dir = tar_folder / cache_name\n",
    "    if cache_dir.exists():\n",
    "        shutil.rmtree(cache_dir)\n",
    "        print(f\" -> Removed {cache_name}\")\n",
    "\n",
    "print(\"\\nPerturbation applied and saved successfully!\")\n",
    "\n",
    "# %% Reload Perturbed Network\n",
    "print(\"Reloading perturbed network from disk...\")\n",
    "network_view_pert = NetworkView(tar_folder)\n",
    "network_pert = network_view_pert.init_network()\n",
    "decoder_pert = network_view_pert.init_decoder()[\"flow\"]\n",
    "decoder_pert.eval()\n",
    "\n",
    "print(\"Perturbed network loaded successfully!\")\n",
    "\n",
    "\n",
    "results_perturbed = evaluate_network(\n",
    "    network_pert,\n",
    "    decoder_pert,\n",
    "    subset_dataset,\n",
    "    output_file=\"data/flyvis_data/perf/sintel_L4_L4_pert_quick_test.csv\"\n",
    ")\n",
    "\n",
    "display(results_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e619920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'metric': ['mean_epe', 'median_epe', 'epe_pixel_3'],\n",
    "    'original': [\n",
    "        results_original[results_original['sequence']=='overall']['mean_epe'].values[0],\n",
    "        results_original[results_original['sequence']=='overall']['median_epe'].values[0],\n",
    "        results_original[results_original['sequence']=='overall']['epe_pixel_3'].values[0] * 100\n",
    "    ],\n",
    "    'perturbed': [\n",
    "        results_perturbed[results_perturbed['sequence']=='overall']['mean_epe'].values[0],\n",
    "        results_perturbed[results_perturbed['sequence']=='overall']['median_epe'].values[0],\n",
    "        results_perturbed[results_perturbed['sequence']=='overall']['epe_pixel_3'].values[0] * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison['change'] = comparison['perturbed'] - comparison['original']\n",
    "comparison['percent_change'] = (comparison['change'] / comparison['original']) * 100\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "display(comparison)\n",
    "\n",
    "# Plot comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot 1: EPE comparison\n",
    "ax1 = axes[0]\n",
    "metrics = ['mean_epe', 'median_epe']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, [comparison[comparison['metric']==m]['original'].values[0] for m in metrics], \n",
    "                width, label='Original', alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, [comparison[comparison['metric']==m]['perturbed'].values[0] for m in metrics], \n",
    "                width, label='Perturbed (L4-L4)', alpha=0.8)\n",
    "\n",
    "ax1.set_ylabel('EPE (pixels)')\n",
    "ax1.set_title('End Point Error Comparison')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(['Mean EPE', 'Median EPE'])\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy comparison\n",
    "ax2 = axes[1]\n",
    "orig_acc = comparison[comparison['metric']=='epe_pixel_3']['original'].values[0]\n",
    "pert_acc = comparison[comparison['metric']=='epe_pixel_3']['perturbed'].values[0]\n",
    "\n",
    "bars = ax2.bar(['Original', 'Perturbed (L4-L4)'], [orig_acc, pert_acc], alpha=0.8)\n",
    "ax2.set_ylabel('% pixels with EPE < 3px')\n",
    "ax2.set_title('Accuracy Comparison')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPerturbation Effect:\")\n",
    "print(f\"  Mean EPE change: {comparison[comparison['metric']=='mean_epe']['change'].values[0]:+.4f} pixels ({comparison[comparison['metric']=='mean_epe']['percent_change'].values[0]:+.2f}%)\")\n",
    "print(f\"  Accuracy change: {comparison[comparison['metric']=='epe_pixel_3']['change'].values[0]:+.2f} percentage points\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Full Dataset Evaluation (Optional)\n",
    "# Uncomment and run this cell to evaluate on the full dataset (takes longer)\n",
    "\n",
    "# %% Full Evaluation (Optional)\n",
    "\"\"\"\n",
    "# Full original network evaluation\n",
    "print(\"FULL EVALUATION - Original Network\")\n",
    "results_full_original = evaluate_network(\n",
    "    network,\n",
    "    decoder,\n",
    "    test_dataset,\n",
    "    output_file=\"data/flyvis_data/perf/sintel_original_full.csv\"\n",
    ")\n",
    "\n",
    "# Full perturbed network evaluation  \n",
    "print(\"\\nFULL EVALUATION - Perturbed Network\")\n",
    "results_full_perturbed = evaluate_network(\n",
    "    network_pert,\n",
    "    decoder_pert,\n",
    "    test_dataset,\n",
    "    output_file=\"data/flyvis_data/perf/sintel_L4_L4_pert_full.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nFull evaluation complete!\")\n",
    "\"\"\"\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
